{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install python3.7","execution_count":66,"outputs":[{"output_type":"stream","text":"Collecting python3.7\n\u001b[31m  ERROR: Could not find a version that satisfies the requirement python3.7 (from versions: none)\u001b[0m\n\u001b[31mERROR: No matching distribution found for python3.7\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!git clone https://github.com/NVIDIA/apex\n#!cd apex\n#!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom pathlib import Path\nfrom typing import *\n\nimport torch\nimport torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.text import *\nfrom fastai.callbacks import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fast_bert.data_cls import BertDataBunch\nfrom sklearn.model_selection import train_test_split\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Config(dict):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n    \n    def set(self, key, val):\n        self[key] = val\n        setattr(self, key, val)\n\nconfig = Config(\n    testing=False,\n    bert_model_name=\"bert-base-multilingual-cased\",\n    max_lr=3e-5,\n    epochs=4,\n    use_fp16=True,\n    bs=4,\n    discriminative=False,\n    max_seq_len=256,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_pretrained_bert import BertTokenizer\nbert_tok = BertTokenizer.from_pretrained(\n    config.bert_model_name,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTPUT_DIR = '/kaggle/working/'#@param {type:\"string\"}\n\ndef convert_catogory_to_num(arg):\n    switcher = { \n        \"art-and-literature\": 0,\n        \"bangladesh\": 1,\n        \"durporobash\": 2,\n        \"economy\": 3,\n        \"education\": 4,\n        \"entertainment\": 5,\n        \"international\": 6,\n        \"life-style\": 7,\n        \"northamerica\": 8,\n        \"opinion\": 9,\n        \"sports\": 10,\n        \"technology\": 11,\n        }\n    return switcher.get(arg, -2) \n","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nimport os\nimport re\n\ndef convert_each_data(temp):\n    data = []\n    for i in temp:\n        data.append(convert_catogory_to_num(i))\n    return data\n\ndef load_dataset():\n    temp = pd.read_pickle('/kaggle/input/40k_bangla_newspaper_article.p')\n    temp = pd.DataFrame(temp)\n    temp.dropna()\n   # print(temp.head())\n   # print(temp[\"content\"][0])\n    print(set(temp.category))\n    data = {}\n    data[\"content\"] = temp[\"content\"]\n    data[\"category\"] = convert_each_data(temp[\"category\"])\n    #print(data[\"content\"][0])\n    return pd.DataFrame.from_dict(data)\n\ndef download_and_load_datasets(size):\n    data = load_dataset()\n    #data = data.drop(data[data[\"category\"] == -2], axis = 1)\n    data = data[data.category != -2]\n    #print(data.head())\n    #print(data[data[\"category\"] == 11])\n    #print(set(data[\"category\"]))\n    print(data.shape[0])\n    data.to_csv('/kaggle/working/news.csv',index=False)\n    train, test = train_test_split(data , test_size = size, random_state = 0)\n    return train, test","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train,test = download_and_load_datasets(0.2)\ntrain.to_csv('/kaggle/working/train.csv', index = False)\ntest.to_csv('/kaggle/working/test.csv', index = False)","execution_count":49,"outputs":[{"output_type":"stream","text":"{'', 'technology', 'entertainment', 'life-style', 'economy', 'education', 'sports', 'durporobash', 'international', 'opinion', 'art-and-literature', 'northamerica', 'bangladesh'}\n39999\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_COLUMN = 'content'\nLABEL_COLUMN = 'category'\n# label_list is the list of labels\nlabel_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\npd.DataFrame(label_list).to_csv('/kaggle/working/label.csv')","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = os.path.join('kaggle', 'working')\nprint(DATA_PATH)\nLABEL_PATH = DATA_PATH","execution_count":64,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for /: 'str' and 'str'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-5569a263f92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDATA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kaggle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'working'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'working'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLABEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"databunch = BertDataBunch(DATA_PATH, LABEL_PATH,\n                          tokenizer= config.bert_model_name,\n                          train_file='train.csv',\n                          val_file='test.csv',\n                          label_file='label.csv',\n                          text_col= DATA_COLUMN,\n                          label_col= LABEL_COLUMN,\n                          batch_size_per_gpu=16,\n                          max_seq_length=256,\n                          multi_gpu=True,\n                          multi_label= False,\n                          model_type='bert')","execution_count":65,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for /: 'str' and 'str'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-e0fdad6bf108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                           \u001b[0mmulti_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                           \u001b[0mmulti_label\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                           model_type='bert')\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/fast_bert/data_cls.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, label_dir, tokenizer, train_file, val_file, test_data, label_file, text_col, label_col, batch_size_per_gpu, max_seq_length, multi_gpu, multi_label, backend, model_type, logger, clear_cache, no_cache)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'cache'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size_per_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size_per_gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FastAiBertTokenizer(BaseTokenizer):\n    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs):\n        self._pretrained_tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n\n    def __call__(self, *args, **kwargs):\n        return self\n\n    def tokenizer(self, t:str) -> List[str]:\n        \"\"\"Limits the maximum sequence length\"\"\"\n        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fastai_bert_vocab = Vocab(list(bert_tok.vocab.keys()))\nfastai_tokenizer = Tokenizer(tok_func=FastAiBertTokenizer(bert_tok, max_seq_len=config.max_seq_len), pre_rules=[], post_rules=[])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertTokenizeProcessor(TokenizeProcessor):\n    def __init__(self, tokenizer):\n        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n\nclass BertNumericalizeProcessor(NumericalizeProcessor):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, vocab=Vocab(list(bert_tok.vocab.keys())), **kwargs)\n\ndef get_bert_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n    \"\"\"\n    Constructing preprocessors for BERT\n    We remove sos/eos tokens since we add that ourselves in the tokenizer.\n    We also use a custom vocabulary to match the numericalization with the original BERT model.\n    \"\"\"\n    return [BertTokenizeProcessor(tokenizer=tokenizer),\n            NumericalizeProcessor(vocab=vocab)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertDataBunch(TextDataBunch):\n    @classmethod\n    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n                label_cols:IntsOrStrs=0, label_delim:str=None, **kwargs) -> DataBunch:\n        \"Create a `TextDataBunch` from DataFrames.\"\n        p_kwargs, kwargs = split_kwargs_by_func(kwargs, get_bert_processor)\n        # use our custom processors while taking tokenizer and vocab as kwargs\n        processor = get_bert_processor(tokenizer=tokenizer, vocab=vocab, **p_kwargs)\n        if classes is None and is_listy(label_cols) and len(label_cols) \n        > 1: classes = label_cols\n        src = ItemLists(path,TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_df(cols=label_cols, classes=classes)\n        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n        return src.databunch(**kwargs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"databunch = BertDataBunch.from_df(\".\", trainpak, validpak,\n                  tokenizer=fastai_tokenizer,\n                  vocab=fastai_bert_vocab,\n                  text_cols=\"text\",\n                  label_cols=label_cols,\n                  bs=config.bs,\n                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"databunch.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_pretrained_bert.modeling import BertConfig, BertForSequenceClassification\nbert_model = BertForSequenceClassification.from_pretrained(config.bert_model_name,num_labels=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(input:Tensor, targs:Tensor)->Rank0Tensor:\n    \"Computes accuracy with `targs` when `input` is bs * n_classes.\"\n    n = targs.shape[0]\n    input = input.argmax(dim=-1).view(n,-1)\n    targs = targs.view(n,-1).long()\n    return (input==targs).float().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.callbacks import *\n\nlearner = Learner(\n    databunch, bert_model,loss_func=nn.BCEWithLogitsLoss(),metrics=accuracy\n)\nif config.use_fp16: learner = learner.to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=6e-3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.fit_one_cycle(7,lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner.recorder.plot_metrics()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}